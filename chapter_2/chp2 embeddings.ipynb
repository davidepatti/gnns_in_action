{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Uncomment the following lines to install the required libraries if you haven't already\n",
    "\n",
    "#! pip install --upgrade networkx matplotlib\n",
    "#!pip install node2vec\n",
    "#!pip install umap-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load the GML file\n",
    "gml_graph = nx.read_gml('polbooks.gml')\n",
    "\n",
    "# Now you can work with the graph object\n",
    "print(len(gml_graph.nodes), len(gml_graph.edges))\n",
    "print(gml_graph.nodes(data=True))  # Print nodes with their attributes\n",
    "print(gml_graph.edges(data=True))  # Print edges with their attributes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary to store counts\n",
    "value_counts = {}\n",
    "\n",
    "# Iterate through the list of tuples\n",
    "for _, attributes in gml_graph.nodes(data=True):\n",
    "    value = attributes['value']\n",
    "    if value in value_counts:\n",
    "        value_counts[value] += 1\n",
    "    else:\n",
    "        value_counts[value] = 1\n",
    "\n",
    "# Print the counts for each 'value'\n",
    "print(value_counts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category proportions\n",
    "\n",
    "[ v/105 for k,v in value_counts.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import networkx as nx\n",
    "\n",
    "# Increase figure size\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "# Change layout\n",
    "pos = nx.kamada_kawai_layout(gml_graph)\n",
    "\n",
    "# Adjust node size (optional, if you have a measure like degree to scale by)\n",
    "# node_sizes = [gml_graph.degree[node] * 100 for node in gml_graph.nodes()]\n",
    "\n",
    "# Adjust font size\n",
    "font_sizes = 10  # or any other size\n",
    "\n",
    "# Define your color mapping\n",
    "color_map = {'l': 'green', 'c': 'orange', 'n': 'grey'}\n",
    "node_colors = [color_map[gml_graph.nodes[node]['value']] for node in gml_graph.nodes()]\n",
    "\n",
    "# Draw nodes\n",
    "nx.draw_networkx_nodes(gml_graph, pos, node_color=node_colors, alpha=0.7)\n",
    "\n",
    "# Draw edges with transparency\n",
    "nx.draw_networkx_edges(gml_graph, pos, alpha=0.1)\n",
    "\n",
    "# Draw labels with font size\n",
    "nx.draw_networkx_labels(gml_graph, pos, font_size=font_sizes)\n",
    "\n",
    "# Remove the axes\n",
    "plt.axis('off')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from node2vec import Node2Vec\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'gml_graph' is your loaded graph from the GML file\n",
    "node2vec = Node2Vec(gml_graph, dimensions=64, walk_length=30, num_walks=200, workers=4)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "# Extract node embeddings into a dictionary\n",
    "embeddings = {str(node): model.wv[str(node)] for node in gml_graph.nodes()}\n",
    "\n",
    "# Prepare a color map and the colors for each node\n",
    "color_map = {'l': 'blue', 'c': 'red', 'n': 'grey'}\n",
    "node_colors = [color_map[gml_graph.nodes[node]['value']] for node in gml_graph.nodes()]\n",
    "\n",
    "# Transform the embeddings into a list of vectors for t-SNE\n",
    "node_embeddings = [embeddings[str(node)] for node in gml_graph.nodes()]\n",
    "node_embeddings_array = np.array(node_embeddings)  # Convert list to NumPy array\n",
    "\n",
    "# Initialize and fit t-SNE\n",
    "tsne_model = TSNE(n_components=2, learning_rate='auto', init='random')\n",
    "tsne_features = tsne_model.fit_transform(node_embeddings_array)\n",
    "\n",
    "# Plot the nodes with t-SNE embeddings and color by their 'value'\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(tsne_features[:, 0], tsne_features[:, 1], color=node_colors, alpha=0.7)\n",
    "\n",
    "# Optionally, add labels for each point\n",
    "#for i, node in enumerate(gml_graph.nodes()):\n",
    "#    plt.annotate(node, (tsne_features[i, 0], tsne_features[i, 1]))\n",
    "\n",
    "plt.xlabel('t-SNE Feature 0')\n",
    "plt.ylabel('t-SNE Feature 1')\n",
    "plt.title('t-SNE Visualization of Node Embeddings')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from node2vec import Node2Vec\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import umap\n",
    "\n",
    "\n",
    "# Assuming 'gml_graph' is your loaded graph from the GML file\n",
    "node2vec = Node2Vec(gml_graph, dimensions=64, walk_length=30, num_walks=200, workers=4)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "# Extract node embeddings into a dictionary\n",
    "embeddings = {str(node): model.wv[str(node)] for node in gml_graph.nodes()}\n",
    "\n",
    "# Prepare a color map and the colors for each node\n",
    "color_map = {'l': 'green', 'c': 'orange', 'n': 'grey'}\n",
    "node_colors = [color_map[gml_graph.nodes[node]['value']] for node in gml_graph.nodes()]\n",
    "\n",
    "# Transform the embeddings into a list of vectors for UMAP\n",
    "node_embeddings = [embeddings[str(node)] for node in gml_graph.nodes()]\n",
    "node_embeddings_array = np.array(node_embeddings)  # Convert list to NumPy array\n",
    "\n",
    "# Initialize and fit UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "umap_features = umap_model.fit_transform(node_embeddings_array)\n",
    "\n",
    "# Plot the nodes with UMAP embeddings and color by their 'value'\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(umap_features[:, 0], umap_features[:, 1], color=node_colors, alpha=0.7)\n",
    "\n",
    "# Optionally, add labels for each point\n",
    "#for i, node in enumerate(gml_graph.nodes()):\n",
    "#    plt.annotate(node, (umap_features[i, 0], umap_features[i, 1]))\n",
    "\n",
    "plt.xlabel('UMAP Feature 0')\n",
    "plt.ylabel('UMAP Feature 1')\n",
    "plt.title('UMAP Visualization of Node Embeddings')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from node2vec import Node2Vec\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import umap\n",
    "\n",
    "# Assuming 'gml_graph' is your loaded graph from the GML file\n",
    "node2vec = Node2Vec(gml_graph, dimensions=64, walk_length=30, num_walks=200, workers=4)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "# Extract node embeddings into a dictionary\n",
    "embeddings = {str(node): model.wv[str(node)] for node in gml_graph.nodes()}\n",
    "\n",
    "# Prepare a color map and the colors for each node\n",
    "color_map = {'l': 'green', 'c': 'orange', 'n': 'grey'}\n",
    "node_colors = [color_map[gml_graph.nodes[node]['value']] for node in gml_graph.nodes()]\n",
    "\n",
    "# Transform the embeddings into a list of vectors for UMAP\n",
    "node_embeddings = [embeddings[str(node)] for node in gml_graph.nodes()]\n",
    "node_embeddings_array = np.array(node_embeddings)  # Convert list to NumPy array\n",
    "\n",
    "# Initialize and fit UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "umap_features = umap_model.fit_transform(node_embeddings_array)\n",
    "\n",
    "# Plot the nodes with UMAP embeddings and color by their 'value'\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Add scatter plot and legend\n",
    "scatter = plt.scatter(umap_features[:, 0], umap_features[:, 1], color=node_colors, alpha=0.7)\n",
    "legend_labels = {\n",
    "    'l': 'Liberal',\n",
    "    'c': 'Conservative',\n",
    "    'n': 'Neutral'\n",
    "}\n",
    "\n",
    "# Create a legend\n",
    "handles = [plt.Line2D([0], [0], marker='o', color='w', label=legend_labels[key], \n",
    "                      markerfacecolor=color_map[key], markersize=10) for key in legend_labels]\n",
    "\n",
    "plt.legend(handles=handles, title='Node Type')\n",
    "\n",
    "# Optionally, add labels for each point\n",
    "#for i, node in enumerate(gml_graph.nodes()):\n",
    "#    plt.annotate(node, (umap_features[i, 0], umap_features[i, 1]))\n",
    "\n",
    "plt.xlabel('UMAP Feature 0')\n",
    "plt.ylabel('UMAP Feature 1')\n",
    "plt.title('UMAP Visualization of Node Embeddings')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'gml_graph' is your loaded graph from the GML file\n",
    "node2vec = Node2Vec(gml_graph, dimensions=64, walk_length=30, num_walks=200, workers=4)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "# Extract node embeddings into a dictionary\n",
    "embeddings = {str(node): model.wv[str(node)] for node in gml_graph.nodes()}\n",
    "\n",
    "# Prepare a color map and the colors for each node\n",
    "color_map = {'l': 'green', 'c': 'orange', 'n': 'grey'}\n",
    "node_colors = [color_map[gml_graph.nodes[node]['value']] for node in gml_graph.nodes()]\n",
    "\n",
    "# Transform the embeddings into a list of vectors for UMAP\n",
    "node_embeddings = [embeddings[str(node)] for node in gml_graph.nodes()]\n",
    "node_embeddings_array = np.array(node_embeddings)  # Convert list to NumPy array\n",
    "\n",
    "# Initialize and fit UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "umap_features = umap_model.fit_transform(node_embeddings_array)\n",
    "\n",
    "##########################\n",
    "\n",
    "# Assuming umap_features are the t-SNE 2D embeddings from your previous code\n",
    "# and gml_graph is your graph object with nodes that have titles as names\n",
    "\n",
    "# Calculate degrees of nodes and sort them\n",
    "degrees = dict(gml_graph.degree())\n",
    "sorted_nodes = sorted(degrees, key=degrees.get, reverse=True)\n",
    "\n",
    "# Decide how many nodes you want to label\n",
    "num_labels = 10  # for example, you want to label the top 10 nodes by degree\n",
    "\n",
    "# Plotting the nodes\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(umap_features[:, 0], umap_features[:, 1], color=node_colors, alpha=0.7)\n",
    "\n",
    "# Adding labels to the chosen nodes\n",
    "for i, node in enumerate(sorted_nodes[:num_labels]):\n",
    "    # Find the index of the node to get its t-SNE coordinates\n",
    "    node_index = list(gml_graph.nodes()).index(node)\n",
    "    plt.annotate(node, (umap_features[node_index, 0], umap_features[node_index, 1]))\n",
    "\n",
    "plt.xlabel('umap Feature 0')\n",
    "plt.ylabel('umap Feature 1')\n",
    "plt.title('umap Visualization of Node Embeddings')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'gml_graph' is your loaded graph from the GML file\n",
    "node2vec = Node2Vec(gml_graph, dimensions=64, walk_length=30, num_walks=200, workers=4)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "# Extract node embeddings into a dictionary\n",
    "embeddings = {str(node): model.wv[str(node)] for node in gml_graph.nodes()}\n",
    "\n",
    "# Prepare a color map for each node class\n",
    "color_map = {\n",
    "    'l': 'green',\n",
    "    'c': 'orange',\n",
    "    'n': 'grey'\n",
    "}\n",
    "\n",
    "# Prepare a shape map for each node class\n",
    "shape_map = {\n",
    "    'l': 'o',  # Circle\n",
    "    'c': '^',  # Triangle\n",
    "    'n': 's'   # Square\n",
    "}\n",
    "\n",
    "# Map each class letter to a full label\n",
    "class_labels = {\n",
    "    'l': 'liberal',\n",
    "    'c': 'conservative',\n",
    "    'n': 'neutral'\n",
    "}\n",
    "\n",
    "# Create the list of embeddings in the same order as gml_graph.nodes()\n",
    "node_embeddings = [embeddings[str(node)] for node in gml_graph.nodes()]\n",
    "node_embeddings_array = np.array(node_embeddings)  # Convert list to NumPy array\n",
    "\n",
    "# Initialize and fit UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "umap_features = umap_model.fit_transform(node_embeddings_array)\n",
    "\n",
    "# Calculate degrees of nodes and sort them (for labeling)\n",
    "degrees = dict(gml_graph.degree())\n",
    "sorted_nodes = sorted(degrees, key=degrees.get, reverse=True)\n",
    "num_labels = 10  # Label the top 10 nodes by degree\n",
    "\n",
    "# --- Plotting Section ---\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 1) Plot each class separately with its own color and marker\n",
    "for class_value in color_map.keys():\n",
    "    # Identify indices in 'umap_features' belonging to this class\n",
    "    class_indices = [\n",
    "        i for i, node in enumerate(gml_graph.nodes()) \n",
    "        if gml_graph.nodes[node]['value'] == class_value\n",
    "    ]\n",
    "\n",
    "    # Scatter plot for this class\n",
    "    plt.scatter(\n",
    "        umap_features[class_indices, 0],\n",
    "        umap_features[class_indices, 1],\n",
    "        color=color_map[class_value],\n",
    "        marker=shape_map[class_value],\n",
    "        alpha=0.7,\n",
    "        label=class_labels[class_value]  # Use full label instead of just 'l', 'c', 'n'\n",
    "    )\n",
    "\n",
    "# 2) Label the top 'num_labels' nodes by degree\n",
    "# for node in sorted_nodes[:num_labels]:\n",
    "#     node_index = list(gml_graph.nodes()).index(node)\n",
    "#     plt.annotate(\n",
    "#         node,\n",
    "#         (umap_features[node_index, 0], umap_features[node_index, 1])\n",
    "#     )\n",
    "\n",
    "# Add legend and labels\n",
    "plt.legend()\n",
    "plt.xlabel('UMAP Feature 0')\n",
    "plt.ylabel('UMAP Feature 1')\n",
    "plt.title('UMAP Visualization of Node Embeddings with Distinct Markers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'gml_graph' is your loaded graph from the GML file\n",
    "node2vec = Node2Vec(gml_graph, dimensions=64, walk_length=30, num_walks=200, workers=4)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "# Extract node embeddings into a dictionary\n",
    "embeddings = {str(node): model.wv[str(node)] for node in gml_graph.nodes()}\n",
    "\n",
    "# Prepare a color map for each node class\n",
    "color_map = {\n",
    "    'l': 'green',\n",
    "    'c': 'orange',\n",
    "    'n': 'grey'\n",
    "}\n",
    "\n",
    "# Prepare a shape map for each node class\n",
    "shape_map = {\n",
    "    'l': 'o',  # Circle\n",
    "    'c': '^',  # Triangle\n",
    "    'n': 's'   # Square\n",
    "}\n",
    "\n",
    "# Create the list of embeddings in the same order as gml_graph.nodes()\n",
    "node_embeddings = [embeddings[str(node)] for node in gml_graph.nodes()]\n",
    "node_embeddings_array = np.array(node_embeddings)  # Convert list to NumPy array\n",
    "\n",
    "# Initialize and fit UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "umap_features = umap_model.fit_transform(node_embeddings_array)\n",
    "\n",
    "# Calculate degrees of nodes and sort them (for labeling)\n",
    "degrees = dict(gml_graph.degree())\n",
    "sorted_nodes = sorted(degrees, key=degrees.get, reverse=True)\n",
    "num_labels = 10  # Label the top 10 nodes by degree\n",
    "\n",
    "# --- Plotting Section ---\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# 1) Plot each class separately with its own color and marker\n",
    "for class_value in color_map.keys():\n",
    "    # Identify indices in 'umap_features' belonging to this class\n",
    "    class_indices = [\n",
    "        i for i, node in enumerate(gml_graph.nodes()) \n",
    "        if gml_graph.nodes[node]['value'] == class_value\n",
    "    ]\n",
    "\n",
    "    # Scatter plot for this class\n",
    "    plt.scatter(\n",
    "        umap_features[class_indices, 0],\n",
    "        umap_features[class_indices, 1],\n",
    "        color=color_map[class_value],\n",
    "        marker=shape_map[class_value],\n",
    "        alpha=0.7,\n",
    "        label=f\"{class_value}\"\n",
    "    )\n",
    "\n",
    "# 2) Label the top 'num_labels' nodes by degree\n",
    "for node in sorted_nodes[:num_labels]:\n",
    "    node_index = list(gml_graph.nodes()).index(node)\n",
    "    plt.annotate(\n",
    "        node,\n",
    "        (umap_features[node_index, 0], umap_features[node_index, 1])\n",
    "    )\n",
    "\n",
    "# Add legend and labels\n",
    "plt.legend()\n",
    "plt.xlabel('UMAP Feature 0')\n",
    "plt.ylabel('UMAP Feature 1')\n",
    "plt.title('UMAP Visualization of Node Embeddings with Distinct Markers')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from node2vec import Node2Vec\n",
    "# import networkx as nx\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'gml_graph' is your loaded graph from the GML file\n",
    "# Set dimensions to 2 for direct plotting\n",
    "node2vec = Node2Vec(gml_graph, dimensions=2, walk_length=30, num_walks=200, workers=4)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "# Extract 2D embeddings into a dictionary\n",
    "embeddings_2d = {str(node): model.wv[str(node)] for node in gml_graph.nodes()}\n",
    "\n",
    "# Prepare a color map and the colors for each node based on their 'value'\n",
    "color_map = {'l': 'green', 'c': 'orange', 'n': 'grey'}\n",
    "node_colors = [color_map[gml_graph.nodes[node]['value']] for node in gml_graph.nodes()]\n",
    "\n",
    "# Prepare the 2D points for plotting\n",
    "points = np.array([embeddings_2d[node] for node in gml_graph.nodes()])\n",
    "\n",
    "# Plot the nodes with their 2D embeddings\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(points[:, 0], points[:, 1], color=node_colors, alpha=0.7)\n",
    "\n",
    "# Optionally, you can label the points\n",
    "# for i, node in enumerate(gml_graph.nodes()):\n",
    "#     plt.annotate(node, (points[i, 0], points[i, 1]), fontsize=9)\n",
    "\n",
    "legend_labels = {\n",
    "    'l': 'Liberal',\n",
    "    'c': 'Conservative',\n",
    "    'n': 'Neutral'\n",
    "}\n",
    "\n",
    "# Create a legend\n",
    "handles = [plt.Line2D([0], [0], marker='o', color='w', label=legend_labels[key], \n",
    "                      markerfacecolor=color_map[key], markersize=10) for key in legend_labels]\n",
    "\n",
    "plt.legend(handles=handles, title='Node Type')\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('Node2Vec Dimension 1')\n",
    "plt.ylabel('Node2Vec Dimension 2')\n",
    "plt.title('Node2Vec Embeddings (2D)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'gml_graph' is your loaded graph from the GML file\n",
    "\n",
    "# Set dimensions=2 for direct 2D plotting\n",
    "node2vec = Node2Vec(gml_graph, dimensions=2, walk_length=30, num_walks=200, workers=4)\n",
    "model = node2vec.fit(window=10, min_count=1, batch_words=4)\n",
    "\n",
    "# Extract 2D embeddings into a dictionary\n",
    "embeddings_2d = {str(node): model.wv[str(node)] for node in gml_graph.nodes()}\n",
    "\n",
    "# Prepare a color map\n",
    "color_map = {\n",
    "    'l': 'green',\n",
    "    'c': 'orange',\n",
    "    'n': 'grey'\n",
    "}\n",
    "\n",
    "# Prepare a shape map\n",
    "shape_map = {\n",
    "    'l': 'o',  # Circle\n",
    "    'c': '^',  # Triangle\n",
    "    'n': 's'   # Square\n",
    "}\n",
    "\n",
    "# Map each class letter to a full legend label\n",
    "legend_labels = {\n",
    "    'l': 'Liberal',\n",
    "    'c': 'Conservative',\n",
    "    'n': 'Neutral'\n",
    "}\n",
    "\n",
    "# Create a list of nodes to maintain a fixed order\n",
    "node_list = list(gml_graph.nodes())\n",
    "\n",
    "# Convert the embeddings to a NumPy array (in the same order as node_list)\n",
    "points = np.array([embeddings_2d[node] for node in node_list])\n",
    "\n",
    "# --- Plotting Section ---\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot each class separately with its own color and marker\n",
    "for class_value in color_map.keys():\n",
    "    # Indices of nodes belonging to this class\n",
    "    class_indices = [\n",
    "        i for i, node in enumerate(node_list)\n",
    "        if gml_graph.nodes[node]['value'] == class_value\n",
    "    ]\n",
    "    \n",
    "    # Scatter plot for this class\n",
    "    plt.scatter(\n",
    "        points[class_indices, 0],  # x-coordinates\n",
    "        points[class_indices, 1],  # y-coordinates\n",
    "        color=color_map[class_value],\n",
    "        marker=shape_map[class_value],\n",
    "        alpha=0.7,\n",
    "        label=legend_labels[class_value]\n",
    "    )\n",
    "\n",
    "# Optionally label specific nodes\n",
    "# for i, node in enumerate(node_list):\n",
    "#     plt.annotate(node, (points[i, 0], points[i, 1]), fontsize=9)\n",
    "\n",
    "# Create a legend from the scatter calls above\n",
    "plt.legend(title='Node Type')\n",
    "\n",
    "# Axes labels and title\n",
    "plt.xlabel('Node2Vec Dimension 1')\n",
    "plt.ylabel('Node2Vec Dimension 2')\n",
    "plt.title('Node2Vec Embeddings (2D) with Distinct Markers & Colors')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Let's assume `points` is the numpy array with your Node2Vec 2D points\n",
    "# and `gml_graph` is your original graph with node labels.\n",
    "\n",
    "# Identify extreme points\n",
    "extreme_indices = {\n",
    "    'leftmost': np.argmin(points[:, 0]),\n",
    "    'rightmost': np.argmax(points[:, 0]),\n",
    "    'topmost': np.argmax(points[:, 1]),\n",
    "    'bottommost': np.argmin(points[:, 1])\n",
    "}\n",
    "\n",
    "# Create a figure for plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Scatter plot of all points\n",
    "plt.scatter(points[:, 0], points[:, 1], alpha=0.7)\n",
    "\n",
    "# Get the node labels from your graph\n",
    "node_labels = list(gml_graph.nodes())\n",
    "\n",
    "# Annotate the extreme points\n",
    "for key, index in extreme_indices.items():\n",
    "    node_label = node_labels[index]\n",
    "    x, y = points[index]\n",
    "    plt.scatter(x, y, color='black')  # Mark the extreme point\n",
    "    plt.annotate(node_label, (x, y), textcoords=\"offset points\", xytext=(5,5), ha='center', fontsize=9)\n",
    "\n",
    "plt.xlabel('Node2Vec Dimension 1')\n",
    "plt.ylabel('Node2Vec Dimension 2')\n",
    "plt.title('Node2Vec Embeddings (2D)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `points` contains your Node2Vec 2D points\n",
    "# and `tsne_features` contains your t-SNE 2D points\n",
    "# and they are aligned with the nodes in `gml_graph`\n",
    "\n",
    "# Identify extreme points in Node2Vec space\n",
    "extreme_indices = {\n",
    "    'leftmost': np.argmin(points[:, 0]),\n",
    "    'rightmost': np.argmax(points[:, 0]),\n",
    "    'topmost': np.argmax(points[:, 1]),\n",
    "    'bottommost': np.argmin(points[:, 1])\n",
    "}\n",
    "\n",
    "# Assuming `tsne_features` is already computed and ready to be plotted\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(tsne_features[:, 0], tsne_features[:, 1], alpha=0.7)\n",
    "\n",
    "# Get the node labels from your graph\n",
    "node_labels = list(gml_graph.nodes())\n",
    "\n",
    "# Annotate the extreme points on the t-SNE plot\n",
    "for position, index in extreme_indices.items():\n",
    "    label = node_labels[index]  # Label of the extreme point\n",
    "    x, y = tsne_features[index]  # Coordinates of the extreme point in t-SNE space\n",
    "    plt.scatter(x, y, color='black')  # Highlight the extreme point\n",
    "    plt.annotate(label, (x, y), textcoords=\"offset points\", xytext=(5,5), ha='center', fontsize=9)\n",
    "\n",
    "plt.xlabel('t-SNE Feature 0')\n",
    "plt.ylabel('t-SNE Feature 1')\n",
    "plt.title('t-SNE Visualization of Node Embeddings')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming `points` contains your Node2Vec 2D points\n",
    "# `tsne_features` contains your t-SNE 2D points\n",
    "# and they are aligned with the nodes in `gml_graph`\n",
    "\n",
    "# Identify extreme points in Node2Vec space\n",
    "extreme_indices = {\n",
    "    'leftmost': np.argmin(points[:, 0]),\n",
    "    'rightmost': np.argmax(points[:, 0]),\n",
    "    'topmost': np.argmax(points[:, 1]),\n",
    "    'bottommost': np.argmin(points[:, 1])\n",
    "}\n",
    "\n",
    "# Create a figure and a set of subplots\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12, 10))  # 2 rows, 1 column\n",
    "\n",
    "# Plot t-SNE Embeddings in the second subplot\n",
    "axs[1].scatter(umap_features[:, 0], umap_features[:, 1], alpha=0.7)\n",
    "# for position, index in extreme_indices.items():\n",
    "#     label = node_labels[index]\n",
    "#     x, y = umap_features[index]\n",
    "#     axs[1].scatter(x, y, color='black')\n",
    "#     axs[1].annotate(label, (x, y), textcoords=\"offset points\", xytext=(5,5), ha='center', fontsize=9)\n",
    "axs[1].set_title('Umap Visualization of Node Embeddings')\n",
    "axs[1].set_xlabel('UMAP Feature 0')\n",
    "axs[1].set_ylabel('t-SNE Feature 1')\n",
    "\n",
    "# Plot Node2Vec Embeddings in the first subplot\n",
    "axs[0].scatter(points[:, 0], points[:, 1], alpha=0.7)\n",
    "# for position, index in extreme_indices.items():\n",
    "#     label = node_labels[index]\n",
    "#     x, y = points[index]\n",
    "#     axs[0].scatter(x, y, color='black')\n",
    "#     axs[0].annotate(label, (x, y), textcoords=\"offset points\", xytext=(5,5), ha='center', fontsize=9)\n",
    "axs[0].set_title('Node2Vec 2D Embeddings without t-SNE')\n",
    "axs[0].set_xlabel('Node2Vec Dimension 1')\n",
    "axs[0].set_ylabel('Node2Vec Dimension 2')\n",
    "\n",
    "\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embedding = model.wv['Losing Bin Laden']  \n",
    "print(node_embedding)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(node_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install the required libraries for GNNs if you haven't already\n",
    "# !pip install torch torchvision\n",
    "#!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "# import torch_geometric\n",
    "# print(torch_geometric.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SimpleGNN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels):\n",
    "        super(SimpleGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # First Graph Convolutional layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        # Second Graph Convolutional layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        # return x\n",
    "        return x, F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils.convert import from_networkx\n",
    "import torch.nn as nn\n",
    "\n",
    "# Convert NetworkX graph to a PyTorch Geometric Data object\n",
    "data = from_networkx(gml_graph)\n",
    "\n",
    "\n",
    "\n",
    "# Initialize node features with Xavier initialization\n",
    "num_features = 64  # Set the desired number of features\n",
    "data.x = torch.empty((data.num_nodes, num_features), dtype=torch.float)  # Create an empty tensor\n",
    "nn.init.xavier_uniform_(data.x)  # Apply Xavier initialization\n",
    "\n",
    "# Instantiate the model\n",
    "model = SimpleGNN(num_features=data.x.shape[1], hidden_channels=64)\n",
    "\n",
    "# Switch the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Perform a forward pass with no gradient computation\n",
    "with torch.no_grad():\n",
    "    gnn_embeddings = model(data.x, data.edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gnn_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Convert to numpy for t-SNE\n",
    "gnn_embeddings_np = gnn_embeddings[0].detach().cpu().numpy() # if using GPU\n",
    "\n",
    "# Initialize and fit UMAP\n",
    "umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2, random_state=42)\n",
    "umap_features = umap_model.fit_transform(gnn_embeddings_np)\n",
    "\n",
    "# Plot the result of t-SNE\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(umap_features[:, 0], umap_features[:, 1], c=node_colors, cmap='viridis', s=15)\n",
    "plt.title('Node Embeddings Visualized with UMAP')\n",
    "plt.xlabel('UMAP Feature 0')\n",
    "plt.ylabel('UMAP Feature 1')\n",
    "\n",
    "\n",
    "legend_labels = {\n",
    "    'l': 'Liberal',\n",
    "    'c': 'Conservative',\n",
    "    'n': 'Neutral'\n",
    "}\n",
    "\n",
    "# Create a legend\n",
    "handles = [plt.Line2D([0], [0], marker='o', color='w', label=legend_labels[key], \n",
    "                      markerfacecolor=color_map[key], markersize=10) for key in legend_labels]\n",
    "\n",
    "plt.legend(handles=handles, title='Node Type')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Section 2.3 Using Node Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Extract labels and handle neutral values\n",
    "labels = []\n",
    "for node, data in gml_graph.nodes(data=True):\n",
    "    if data['value'] == 'c':\n",
    "        labels.append('right')\n",
    "    elif data['value'] == 'l':\n",
    "        labels.append('left')\n",
    "    else:  # Handle neutral and missing values\n",
    "        labels.append('neutral')\n",
    "\n",
    "labels = np.array(labels)\n",
    "\n",
    "# Random seed for reproducibility\n",
    "random.seed(52)\n",
    "\n",
    "# Indices of all nodes\n",
    "indices = list(range(len(labels)))\n",
    "\n",
    "# Percentage of data to keep as labelled\n",
    "labelled_percentage = 0.2  # e.g., 10% as labelled\n",
    "\n",
    "# Select a subset of indices to remain labelled\n",
    "labelled_indices = random.sample(indices, int(labelled_percentage * len(labels)))\n",
    "\n",
    "# Initialize masks for labelled and unlabelled data\n",
    "labelled_mask = np.zeros(len(labels), dtype=bool)\n",
    "unlabelled_mask = np.ones(len(labels), dtype=bool)\n",
    "\n",
    "# Update masks\n",
    "labelled_mask[labelled_indices] = True\n",
    "unlabelled_mask[labelled_indices] = False\n",
    "\n",
    "# Use masks to split the dataset\n",
    "labelled_labels = labels[labelled_mask]\n",
    "unlabelled_labels = labels[unlabelled_mask]  # You won't use these labels during training\n",
    "\n",
    "label_mapping = {'left': 0, 'right': 1, 'neutral': 2}\n",
    "numeric_labels = np.array([label_mapping[label] for label in labels])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'left': 0, 'right': 1, 'neutral': 2}\n",
    "numeric_labels = np.array([label_mapping[label] for label in labels])\n",
    "\n",
    "\n",
    "# For GNN embeddings\n",
    "X_train_gnn, y_train_gnn = gnn_embeddings[0][labelled_mask], numeric_labels[labelled_mask]\n",
    "\n",
    "# For N2V embeddings\n",
    "# Ensure node2vec embeddings are in the same order as labels\n",
    "X_n2v = np.array([embeddings[str(node)] for node in gml_graph.nodes()])\n",
    "X_train_n2v, y_train_n2v = X_n2v[labelled_mask], numeric_labels[labelled_mask]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Classifier for GNN embeddings\n",
    "clf_gnn = RandomForestClassifier()\n",
    "clf_gnn.fit(X_train_gnn, y_train_gnn)\n",
    "\n",
    "# Classifier for N2V embeddings\n",
    "clf_n2v = RandomForestClassifier()\n",
    "clf_n2v.fit(X_train_n2v, y_train_n2v)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Predictions with GNN embeddings\n",
    "y_pred_gnn = clf_gnn.predict(gnn_embeddings[0][unlabelled_mask])\n",
    "# Evaluate GNN classifier\n",
    "gnn_accuracy = accuracy_score(numeric_labels[unlabelled_mask], y_pred_gnn)\n",
    "gnn_f1_score = f1_score(numeric_labels[unlabelled_mask], y_pred_gnn, average='weighted')\n",
    "\n",
    "# Predictions with N2V embeddings\n",
    "y_pred_n2v = clf_n2v.predict(X_n2v[unlabelled_mask])\n",
    "# Evaluate N2V classifier\n",
    "n2v_accuracy = accuracy_score(numeric_labels[unlabelled_mask], y_pred_n2v)\n",
    "n2v_f1_score = f1_score(numeric_labels[unlabelled_mask], y_pred_n2v, average='weighted')\n",
    "\n",
    "print(f\"GNN Accuracy: {gnn_accuracy:.4f}\")\n",
    "print(f\"GNN F1 Score: {gnn_f1_score:.4f}\")\n",
    "print(f\"N2V Accuracy: {n2v_accuracy:.4f}\")\n",
    "print(f\"N2V F1 Score: {n2v_f1_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def adjust_proba(y_pred_proba, all_classes):\n",
    "    # Check if predicted probabilities cover all classes\n",
    "    if y_pred_proba.shape[1] != len(all_classes):\n",
    "        # Create a new array with a column for each class\n",
    "        adjusted_proba = np.zeros((y_pred_proba.shape[0], len(all_classes)))\n",
    "        # Fill in the probabilities for the classes that the classifier provided\n",
    "        for idx, cls in enumerate(clf_gnn.classes_):  # Assuming clf_gnn.classes_ is in the order of the output probabilities\n",
    "            class_idx = np.where(all_classes == cls)[0][0]\n",
    "            adjusted_proba[:, class_idx] = y_pred_proba[:, idx]\n",
    "        return adjusted_proba\n",
    "    else:\n",
    "        return y_pred_proba\n",
    "\n",
    "all_classes = np.array([0, 1, 2])  # Assuming these are the numeric labels for 'left', 'right', 'neutral'\n",
    "y_pred_proba_n2v = clf_n2v.predict_proba(X_n2v[unlabelled_mask])\n",
    "#y_pred_proba_gnn = clf_gnn.predict_proba(gnn_embeddings[0][unlabelled_mask])\n",
    "y_pred_proba_gnn = clf_gnn.predict_proba(gnn_embeddings[0])\n",
    "\n",
    "\n",
    "# Adjust the predicted probabilities\n",
    "y_pred_proba_gnn_adjusted = adjust_proba(y_pred_proba_gnn, all_classes)\n",
    "y_pred_proba_n2v_adjusted = adjust_proba(y_pred_proba_n2v, all_classes)\n",
    "\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Compute log loss using the adjusted probabilities\n",
    "log_loss_gnn = log_loss(numeric_labels[unlabelled_mask], y_pred_proba_gnn_adjusted[unlabelled_mask], labels=all_classes)\n",
    "log_loss_n2v = log_loss(numeric_labels[unlabelled_mask], y_pred_proba_n2v_adjusted, labels=all_classes)\n",
    "\n",
    "print(f\"GNN Log Loss: {log_loss_gnn:.4f}\")\n",
    "print(f\"N2V Log Loss: {log_loss_n2v:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_labels[unlabelled_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_proba_gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_n2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NetworkX graph to a PyTorch Geometric Data object\n",
    "data = from_networkx(gml_graph)\n",
    "\n",
    "# Prepare the node features (using Node2Vec embeddings)\n",
    "# node_features = torch.tensor(node_embeddings, dtype=torch.float)\n",
    "\n",
    "# Add node features to data\n",
    "# data.x = node_features\n",
    "\n",
    "# Note: If you have no initial node features, you could alternatively initialize them randomly\n",
    "data.x = torch.randn((data.num_nodes, 64), dtype=torch.float)\n",
    "\n",
    "train_labels = torch.tensor(numeric_labels, dtype=torch.long)[labelled_mask]\n",
    "\n",
    "# Assuming 'labelled_mask' is a boolean array indicating which nodes are labelled\n",
    "data.train_mask = torch.tensor(labelled_mask, dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of input features and output classes\n",
    "num_features = data.num_features  # Assuming data.x contains the node features\n",
    "num_classes = 3  # Assuming you have 3 classes in your classification task\n",
    "\n",
    "# Initialize the model\n",
    "class SimpleGNN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels):\n",
    "        super(SimpleGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # First Graph Convolutional layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        # Second Graph Convolutional layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return x, F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Version with 4 GCN layers\n",
    "class SimpleGNN(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels):\n",
    "        super(SimpleGNN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, hidden_channels)  # Add another GCN layer\n",
    "        self.conv4 = GCNConv(hidden_channels, hidden_channels)  # Add another GCN layer\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # First Graph Convolutional layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        # Second Graph Convolutional layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        # Third Graph Convolutional layer\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        \n",
    "        # Fourth Graph Convolutional layer\n",
    "        x = self.conv4(x, edge_index)\n",
    "        \n",
    "        return x, F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleGNN(num_features=data.x.shape[1], hidden_channels=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleGNN_2(torch.nn.Module):\n",
    "    def __init__(self, num_features, num_classes):\n",
    "        super(SimpleGNN_2, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# uncomment the line below to use the 2-layer GNN model with a single output layer for classification\n",
    "#model = SimpleGNN_2(num_features=num_features, num_classes=num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convert NetworkX graph to a PyTorch Geometric Data object\n",
    "data = from_networkx(gml_graph)\n",
    "\n",
    "# Prepare the node features (using Node2Vec embeddings)\n",
    "# node_features = torch.tensor(node_embeddings, dtype=torch.float)\n",
    "\n",
    "# Add node features to data\n",
    "# data.x = node_features\n",
    "\n",
    "# Note: If you have no initial node features, you could alternatively initialize them randomly\n",
    "data.x = torch.randn((data.num_nodes, 64), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_labels = torch.tensor(numeric_labels, dtype=torch.long)[labelled_mask]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Convert NetworkX graph to a PyTorch Geometric Data object\n",
    "data = from_networkx(gml_graph)\n",
    "\n",
    "# Prepare the node features (using Node2Vec embeddings)\n",
    "# node_features = torch.tensor(node_embeddings, dtype=torch.float)\n",
    "\n",
    "# Add node features to data\n",
    "# data.x = node_features\n",
    "\n",
    "# Note: If you have no initial node features, you could alternatively initialize them randomly\n",
    "data.x = torch.randn((data.num_nodes, 64), dtype=torch.float)\n",
    "\n",
    "train_labels = torch.tensor(numeric_labels, dtype=torch.long)[labelled_mask]\n",
    "\n",
    "# Assuming 'labelled_mask' is a boolean array indicating which nodes are labelled\n",
    "data.train_mask = torch.tensor(labelled_mask, dtype=torch.bool)\n",
    "\n",
    "loss_fn = torch.nn.NLLLoss()\n",
    "\n",
    "for epoch in range(200):  # Number of epochs\n",
    "    optimizer.zero_grad()\n",
    "    # Pass both node features and edge_index to the model\n",
    "    model_out = model(data.x, data.edge_index)\n",
    "\n",
    "    # Handle models that return (embeddings, logits) or just logits\n",
    "    if isinstance(model_out, (tuple, list)):\n",
    "        out = model_out[-1]\n",
    "    else:\n",
    "        out = model_out\n",
    "\n",
    "    # Apply the training mask to select only the outputs for the labelled nodes\n",
    "    out_masked = out[data.train_mask]\n",
    "\n",
    "    # Compute the loss using only the labelled nodes\n",
    "    loss = loss_fn(out_masked, train_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "\n",
    "    if epoch % 10 == 0:  # Print loss every 10 epochs\n",
    "        print(f'Epoch {epoch}, Log Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get model output (handle models that return tuples like (embeddings, logits))\n",
    "model_out = model(data.x, data.edge_index)\n",
    "if isinstance(model_out, (tuple, list)):\n",
    "\tout_all = model_out[-1]  # assume last element contains logits/log-probs\n",
    "else:\n",
    "\tout_all = model_out\n",
    "\n",
    "# Ensure out_all is a torch tensor (and on the right device)\n",
    "if not isinstance(out_all, torch.Tensor):\n",
    "\tout_all = torch.tensor(out_all, dtype=torch.float)\n",
    "\n",
    "# Convert the numpy boolean mask to a torch bool tensor on the same device\n",
    "mask = torch.tensor(labelled_mask, dtype=torch.bool, device=out_all.device)\n",
    "\n",
    "# Select only the labeled nodes' outputs\n",
    "out_masked = out_all[mask]\n",
    "\n",
    "# Move training labels to the same device\n",
    "train_labels = train_labels.to(out_masked.device)\n",
    "\n",
    "# Compute the loss using only the labeled nodes\n",
    "loss = loss_fn(out_masked, train_labels)\n",
    "\n",
    "print(f'Training Log Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Pass the entire dataset through the model to obtain predicted probabilities for all nodes\n",
    "with torch.no_grad():\n",
    "    out = model(data.x, data.edge_index)\n",
    "\n",
    "# Adjust the predicted probabilities\n",
    "y_pred_proba_gnn_adjusted = adjust_proba(y_pred_proba_gnn, all_classes)\n",
    "\n",
    "# Select only the predicted probabilities for the unlabelled nodes\n",
    "y_pred_proba_gnn_unlabelled = y_pred_proba_gnn_adjusted[unlabelled_mask]\n",
    "\n",
    "# Compute log loss using the adjusted probabilities for unlabelled nodes\n",
    "log_loss_gnn = log_loss(numeric_labels[unlabelled_mask], y_pred_proba_gnn_unlabelled, labels=all_classes)\n",
    "\n",
    "print(f\"GNN Log Loss: {log_loss_gnn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Convert NetworkX graph to a PyTorch Geometric Data object\n",
    "data = from_networkx(gml_graph)\n",
    "\n",
    "# Prepare the node features (using Node2Vec embeddings)\n",
    "# node_features = torch.tensor(node_embeddings, dtype=torch.float)\n",
    "\n",
    "# Add node features to data\n",
    "# data.x = node_features\n",
    "\n",
    "# Note: If you have no initial node features, you could alternatively initialize them randomly\n",
    "data.x = torch.randn((data.num_nodes, 64), dtype=torch.float)\n",
    "\n",
    "train_labels = torch.tensor(numeric_labels, dtype=torch.long)[labelled_mask]\n",
    "\n",
    "# Assuming 'labelled_mask' is a boolean array indicating which nodes are labelled\n",
    "data.train_mask = torch.tensor(labelled_mask, dtype=torch.bool)\n",
    "\n",
    "# Initialize an empty array to store the predicted probabilities\n",
    "y_pred_proba_gnn = []\n",
    "\n",
    "for epoch in range(1):  # Number of epochs\n",
    "    optimizer.zero_grad()\n",
    "    # Pass both node features and edge_index to the model\n",
    "    model_out = model(data.x, data.edge_index)\n",
    "    # handle models that return tuples (e.g., (embeddings, log_probs))\n",
    "    if isinstance(model_out, (tuple, list)):\n",
    "        out = model_out[-1]  # assume last element is the log-probabilities\n",
    "    else:\n",
    "        out = model_out\n",
    "    # Apply the training mask to select only the outputs for the labelled nodes\n",
    "    out_masked = out[data.train_mask]\n",
    "    # Compute the loss using only the labelled nodes (NLLLoss expects log-probs)\n",
    "    loss = loss_fn(out_masked, train_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:  # Print loss every 10 epochs\n",
    "        print(f'Epoch {epoch}, Log Loss: {loss.item()}')\n",
    "\n",
    "# Pass the entire dataset through the model to obtain predicted probabilities for all nodes\n",
    "with torch.no_grad():\n",
    "    model_out = model(data.x, data.edge_index)\n",
    "    if isinstance(model_out, (tuple, list)):\n",
    "        out = model_out[-1]\n",
    "    else:\n",
    "        out = model_out\n",
    "    # 'out' is log-probabilities (log_softmax); convert to probabilities with exp and move to CPU\n",
    "    y_pred_proba_gnn = out.exp().cpu().numpy()\n",
    "\n",
    "# Adjust the predicted probabilities\n",
    "y_pred_proba_gnn_adjusted = adjust_proba(y_pred_proba_gnn, all_classes)\n",
    "\n",
    "# Select only the predicted probabilities for the unlabelled nodes\n",
    "y_pred_proba_gnn_unlabelled = y_pred_proba_gnn_adjusted[unlabelled_mask]\n",
    "\n",
    "# Compute log loss using the adjusted probabilities for unlabelled nodes\n",
    "log_loss_gnn = log_loss(numeric_labels[unlabelled_mask], y_pred_proba_gnn_unlabelled, labels=all_classes)\n",
    "\n",
    "print(f\"GNN Log Loss: {log_loss_gnn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Convert NetworkX graph to a PyTorch Geometric Data object\n",
    "data = from_networkx(gml_graph)\n",
    "\n",
    "# Prepare the node features (using Node2Vec embeddings)\n",
    "node_features = torch.tensor(node_embeddings, dtype=torch.float)\n",
    "\n",
    "# Add node features to data\n",
    "data.x = node_features\n",
    "\n",
    "# Note: If you have no initial node features, you could alternatively initialize them randomly\n",
    "# data.x = torch.randn((data.num_nodes, 64), dtype=torch.float)\n",
    "\n",
    "train_labels = torch.tensor(numeric_labels, dtype=torch.long)[labelled_mask]\n",
    "\n",
    "# Assuming 'labelled_mask' is a boolean array indicating which nodes are labelled\n",
    "data.train_mask = torch.tensor(labelled_mask, dtype=torch.bool)\n",
    "\n",
    "# Initialize an empty array to store the predicted probabilities\n",
    "y_pred_proba_gnn = []\n",
    "\n",
    "for epoch in range(2000):  # Number of epochs\n",
    "    optimizer.zero_grad()\n",
    "    # Pass both node features and edge_index to the model\n",
    "    model_out = model(data.x, data.edge_index)\n",
    "    # Handle different possible return types (single tensor, tuple/list of tensors, etc.)\n",
    "    if isinstance(model_out, (tuple, list)):\n",
    "        out = model_out[-1]  # assume logits/probabilities are the last element\n",
    "    else:\n",
    "        out = model_out\n",
    "    # Apply the training mask to select only the outputs for the labelled nodes\n",
    "    out_masked = out[data.train_mask]\n",
    "    # Compute the loss using only the labelled nodes\n",
    "    loss = loss_fn(out_masked, train_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:  # Print loss every 10 epochs\n",
    "        print(f'Epoch {epoch}, Log Loss: {loss.item()}')\n",
    "\n",
    "# Pass the entire dataset through the model to obtain predicted probabilities for all nodes\n",
    "with torch.no_grad():\n",
    "    model_out = model(data.x, data.edge_index)\n",
    "    if isinstance(model_out, (tuple, list)):\n",
    "        out = model_out[-1]\n",
    "    else:\n",
    "        out = model_out\n",
    "    # Convert the output into probabilities using softmax and move to CPU before converting to numpy\n",
    "    y_pred_proba_gnn = torch.softmax(out, dim=1).cpu().numpy()\n",
    "\n",
    "# Adjust the predicted probabilities\n",
    "y_pred_proba_gnn_adjusted = adjust_proba(y_pred_proba_gnn, all_classes)\n",
    "\n",
    "# Apply the unlabelled mask to select only the predicted probabilities for unlabelled nodes\n",
    "y_pred_proba_gnn_unlabelled = y_pred_proba_gnn_adjusted[unlabelled_mask]\n",
    "\n",
    "# Compute log loss using the adjusted probabilities\n",
    "log_loss_gnn = log_loss(numeric_labels[unlabelled_mask], y_pred_proba_gnn_unlabelled, labels=all_classes)\n",
    "\n",
    "print(f\"GNN Log Loss: {log_loss_gnn:.4f}\")\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Convert predicted probabilities to predicted labels\n",
    "y_pred_gnn = np.argmax(y_pred_proba_gnn_unlabelled, axis=1)\n",
    "\n",
    "# Compute F1 score\n",
    "f1_gnn = f1_score(numeric_labels[unlabelled_mask], y_pred_gnn, average='weighted')\n",
    "\n",
    "print(f\"GNN F1 Score: {f1_gnn:.4f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Get predicted labels by selecting the class with the highest probability for each node\n",
    "y_pred_labels_gnn = np.argmax(y_pred_proba_gnn_unlabelled, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_gnn = accuracy_score(numeric_labels[unlabelled_mask], y_pred_labels_gnn)\n",
    "\n",
    "print(f\"GNN Accuracy: {accuracy_gnn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10, verbose=True)\n",
    "patience=50\n",
    "best_loss = float('inf')\n",
    "best_epoch = 0\n",
    "\n",
    "\n",
    "for epoch in range(2000):  # Number of epochs\n",
    "    optimizer.zero_grad()\n",
    "    # Pass both node features and edge_index to the model\n",
    "    model_out = model(data.x, data.edge_index)\n",
    "    if (isinstance(model_out, (tuple, list))):\n",
    "        out = model_out[-1]  # assume last element is the log-probabilities\n",
    "    else:\n",
    "        out = model_out\n",
    "    # Apply the training mask to select only the outputs for the labelled nodes\n",
    "    out_masked = out[data.train_mask]\n",
    "    # Compute the loss using only the labelled nodes\n",
    "    loss = loss_fn(out_masked, train_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Update learning rate scheduler\n",
    "    scheduler.step(loss)\n",
    "\n",
    "    if epoch % 10 == 0:  # Print loss every 10 epochs\n",
    "        print(f'Epoch {epoch}, Log Loss: {loss.item()}')\n",
    "\n",
    "    # Check for early stopping based on validation loss (not implemented here)\n",
    "    if loss < best_loss:\n",
    "        best_loss = loss\n",
    "        best_epoch = epoch\n",
    "    elif epoch - best_epoch > patience:  # Patience is the number of epochs to wait before early stopping\n",
    "        print(\"Early stopping triggered.\")\n",
    "        break\n",
    "\n",
    "        # Convert predicted probabilities to predicted labels\n",
    "y_pred_gnn = np.argmax(y_pred_proba_gnn_unlabelled, axis=1)\n",
    "\n",
    "# Compute F1 score\n",
    "f1_gnn = f1_score(numeric_labels[unlabelled_mask], y_pred_gnn, average='weighted')\n",
    "\n",
    "print(f\"GNN F1 Score: {f1_gnn:.4f}\")\n",
    "\n",
    "\n",
    "# Get predicted labels by selecting the class with the highest probability for each node\n",
    "y_pred_labels_gnn = np.argmax(y_pred_proba_gnn_unlabelled, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_gnn = accuracy_score(numeric_labels[unlabelled_mask], y_pred_labels_gnn)\n",
    "\n",
    "print(f\"GNN Accuracy: {accuracy_gnn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Convert NetworkX graph to a PyTorch Geometric Data object\n",
    "data = from_networkx(gml_graph)\n",
    "\n",
    "# Prepare the node features (using Node2Vec embeddings)\n",
    "# node_features = torch.tensor(node_embeddings, dtype=torch.float)\n",
    "\n",
    "# Add node features to data\n",
    "# data.x = node_features\n",
    "\n",
    "# Note: If you have no initial node features, you could alternatively initialize them randomly\n",
    "data.x = torch.randn((data.num_nodes, 64), dtype=torch.float)\n",
    "\n",
    "train_labels = torch.tensor(numeric_labels, dtype=torch.long)[labelled_mask]\n",
    "\n",
    "# Assuming 'labelled_mask' is a boolean array indicating which nodes are labelled\n",
    "data.train_mask = torch.tensor(labelled_mask, dtype=torch.bool)\n",
    "\n",
    "# Initialize an empty array to store the predicted probabilities\n",
    "y_pred_proba_gnn = []\n",
    "\n",
    "for epoch in range(3000):  # Number of epochs\n",
    "    optimizer.zero_grad()\n",
    "    # Pass both node features and edge_index to the model\n",
    "    out_model = model(data.x, data.edge_index)\n",
    "    if isinstance(out_model, (tuple, list)):\n",
    "        out = out_model[-1]  # assume last element is the log-probabilities\n",
    "    else:\n",
    "        out = out_model\n",
    "    # Apply the training mask to select only the outputs for the labelled nodes\n",
    "    out_masked = out[data.train_mask]\n",
    "    # Compute the loss using only the labelled nodes\n",
    "    loss = loss_fn(out_masked, train_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:  # Print loss every 10 epochs\n",
    "        print(f'Epoch {epoch}, Log Loss: {loss.item()}')\n",
    "\n",
    "# Pass the entire dataset through the model to obtain predicted probabilities for all nodes\n",
    "with torch.no_grad():\n",
    "    model_out = model(data.x, data.edge_index)\n",
    "    if isinstance(model_out, (tuple, list)):\n",
    "        out = model_out[-1]  # assume last element is the log-probabilities\n",
    "    else:\n",
    "        out = model_out\n",
    "    # Convert the output into probabilities using softmax\n",
    "    y_pred_proba_gnn = torch.softmax(out, dim=1).numpy()\n",
    "\n",
    "# Adjust the predicted probabilities\n",
    "y_pred_proba_gnn_adjusted = adjust_proba(y_pred_proba_gnn, all_classes)\n",
    "\n",
    "# Apply the unlabelled mask to select only the predicted probabilities for unlabelled nodes\n",
    "y_pred_proba_gnn_unlabelled = y_pred_proba_gnn_adjusted[unlabelled_mask]\n",
    "\n",
    "# Compute log loss using the adjusted probabilities\n",
    "log_loss_gnn = log_loss(numeric_labels[unlabelled_mask], y_pred_proba_gnn_unlabelled, labels=all_classes)\n",
    "\n",
    "print(f\"GNN Log Loss: {log_loss_gnn:.4f}\")\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Convert predicted probabilities to predicted labels\n",
    "y_pred_gnn = np.argmax(y_pred_proba_gnn_unlabelled, axis=1)\n",
    "\n",
    "# Compute F1 score\n",
    "f1_gnn = f1_score(numeric_labels[unlabelled_mask], y_pred_gnn, average='weighted')\n",
    "\n",
    "print(f\"GNN F1 Score: {f1_gnn:.4f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Get predicted labels by selecting the class with the highest probability for each node\n",
    "y_pred_labels_gnn = np.argmax(y_pred_proba_gnn_unlabelled, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_gnn = accuracy_score(numeric_labels[unlabelled_mask], y_pred_labels_gnn)\n",
    "\n",
    "print(f\"GNN Accuracy: {accuracy_gnn:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Convert predicted probabilities to predicted labels\n",
    "y_pred_gnn = np.argmax(y_pred_proba_gnn_unlabelled, axis=1)\n",
    "\n",
    "# Compute F1 score\n",
    "f1_gnn = f1_score(numeric_labels[unlabelled_mask], y_pred_gnn, average='weighted')\n",
    "\n",
    "print(f\"GNN F1 Score: {f1_gnn:.4f}\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Get predicted labels by selecting the class with the highest probability for each node\n",
    "y_pred_labels_gnn = np.argmax(y_pred_proba_gnn_unlabelled, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_gnn = accuracy_score(numeric_labels[unlabelled_mask], y_pred_labels_gnn)\n",
    "\n",
    "print(f\"GNN Accuracy: {accuracy_gnn:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Assuming 'model' is your trained GNN model\n",
    "# Assuming 'data' contains your input graph data\n",
    "# Assuming 'numeric_labels' contains the numeric labels\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Pass the entire dataset through the model to obtain node embeddings\n",
    "with torch.no_grad():\n",
    "    mode_out = model(data.x, data.edge_index)\n",
    "    if isinstance(mode_out, (tuple, list)):\n",
    "        out = mode_out[0]  # assume the first element contains the embeddings\n",
    "    else:\n",
    "        out = mode_out\n",
    "\n",
    "# Extract embeddings from the output of the GNN model\n",
    "node_embeddings = out.numpy()\n",
    "\n",
    "# Reduce dimensionality of embeddings using t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "embeddings_2d = tsne.fit_transform(node_embeddings)\n",
    "\n",
    "# Define colors for different labels\n",
    "label_colors = {0: 'blue', 1: 'red', 2: 'grey'}\n",
    "\n",
    "# Plot the embeddings with colored points based on true labels\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(len(embeddings_2d)):\n",
    "    plt.scatter(embeddings_2d[i, 0], embeddings_2d[i, 1], color=label_colors[numeric_labels[i]], s=10)  # Adjust 's' for point size\n",
    "plt.title('t-SNE Visualization of Node Embeddings')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "\n",
    "# Create legend\n",
    "handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=5, label=label) for label, color in label_colors.items()]\n",
    "plt.legend(handles=handles, title='Labels', loc='best')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Assuming 'model' is your trained GNN model\n",
    "# Assuming 'data' contains your input graph data\n",
    "# Assuming 'numeric_labels' contains the numeric labels\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Pass the entire dataset through the model to obtain node embeddings\n",
    "with torch.no_grad():\n",
    "    model_out = model(data.x, data.edge_index)\n",
    "    if isinstance(model_out, (tuple, list)):\n",
    "        out = model_out[0]  # assume the first element contains the embeddings\n",
    "    else:\n",
    "        out = model_out\n",
    "\n",
    "# Extract embeddings from the output of the GNN model\n",
    "node_embeddings = out.numpy()\n",
    "\n",
    "# Reduce dimensionality of embeddings using t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "embeddings_2d = tsne.fit_transform(node_embeddings)\n",
    "\n",
    "# Define colors for different labels\n",
    "label_colors = {0: 'blue', 1: 'red', 2: 'grey'}\n",
    "\n",
    "# Plot the embeddings with colored points based on true labels\n",
    "plt.figure(figsize=(10, 8))\n",
    "for i in range(len(embeddings_2d)):\n",
    "    plt.scatter(embeddings_2d[i, 0], embeddings_2d[i, 1], color=label_colors[numeric_labels[i]], s=10)  # Adjust 's' for point size\n",
    "plt.title('t-SNE Visualization of Node Embeddings')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "\n",
    "# Create legend\n",
    "handles = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=color, markersize=5, label=label) for label, color in label_colors.items()]\n",
    "plt.legend(handles=handles, title='Labels', loc='best')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple graph with 5 nodes and labels\n",
    "G = nx.Graph()\n",
    "G.add_edges_from([(0, 1), (0, 2), (1, 2), (3, 4)])\n",
    "labels = np.array(['A', 'B', 'C', 'D', 'E'])  # Node labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGNN_test(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleGNN_test, self).__init__()\n",
    "        self.conv1 = GCNConv(1, 2)  # Assuming 1-dimensional features, outputting 2-dimensional embeddings\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Convert to PyTorch Geometric Data\n",
    "data = from_networkx(G)\n",
    "data.x = torch.ones(data.num_nodes, 1)  # Dummy features\n",
    "\n",
    "# Initialize and apply GNN\n",
    "model = SimpleGNN_test()\n",
    "with torch.no_grad():\n",
    "    gnn_embeddings = model(data).numpy()\n",
    "\n",
    "print(\"GNN Embeddings aligned with node order:\\n\", gnn_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "node2vec = Node2Vec(G, dimensions=2, walk_length=10, num_walks=5, workers=1)\n",
    "model = node2vec.fit(window=2)\n",
    "n2v_embeddings = np.array([model.wv[str(i)] for i in range(len(G))])\n",
    "\n",
    "print(\"Node2Vec Embeddings (need alignment):\\n\", n2v_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For GNN, embeddings are already aligned with labels\n",
    "print(\"GNN Labels aligned:\", labels)\n",
    "\n",
    "# For Node2Vec, demonstrate the need for alignment\n",
    "aligned_labels = np.array([labels[int(node)] for node in model.wv.index_to_key])\n",
    "print(\"Node2Vec Labels after alignment:\", aligned_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
